{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Model with residual connections and batch normalization"
      ],
      "metadata": {
        "id": "idmr1W3q5ahU"
      },
      "id": "idmr1W3q5ahU"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1f431690",
      "metadata": {
        "scrolled": true,
        "id": "1f431690"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_datasets as tfds\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "35511d2e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35511d2e",
        "outputId": "55dd88be-bbf5-4ac8-c40b-6091bb53bce8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e4d7998",
      "metadata": {
        "id": "9e4d7998"
      },
      "source": [
        "Loading train, validation and test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4R0gNgH6HPRL"
      },
      "outputs": [],
      "source": [
        "ds = tfds.load('malaria', \n",
        "               split=('train[:80%]', 'train[80%:]'), \n",
        "               shuffle_files=False,\n",
        "              data_dir='/content/gdrive/MyDrive/datasets/Malaria',\n",
        "               batch_size=32,\n",
        "              download=True,\n",
        "              as_supervised=True,\n",
        "              with_info=False)"
      ],
      "id": "4R0gNgH6HPRL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model building"
      ],
      "metadata": {
        "id": "ep3vZn0KcBJp"
      },
      "id": "ep3vZn0KcBJp"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "L4VUYwMSDWYf"
      },
      "outputs": [],
      "source": [
        "def build_model(init_filters, kernel_size, num_resid):\n",
        "    '''I keep the number of filters the same in all layers in this version'''\n",
        "    inputs = keras.Input(shape=(None, None, 3))\n",
        "    x = keras.layers.Rescaling(scale=1.0 / 255)(inputs)\n",
        "    x = keras.layers.Conv2D(\n",
        "      filters=init_filters,\n",
        "      kernel_size=kernel_size,\n",
        "      strides=(1, 1),\n",
        "      padding=\"same\")(x)\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "    x = keras.layers.Activation(\"relu\")(x)\n",
        "    x = keras.layers.MaxPooling2D(\n",
        "        pool_size=(2, 2), \n",
        "        strides=None, \n",
        "        padding=\"same\")(x)\n",
        "    prev_block_output = x\n",
        "    for i in range(1, num_resid + 1):\n",
        "        # i is the number of blocks with residual connections\n",
        "      x = keras.layers.Conv2D(\n",
        "          filters=init_filters,\n",
        "          kernel_size=kernel_size,\n",
        "          strides=(1, 1),\n",
        "          padding=\"same\")(x)\n",
        "      x = keras.layers.BatchNormalization()(x)\n",
        "      x = keras.layers.Activation(\"relu\")(x)\n",
        "      x = keras.layers.Conv2D(\n",
        "          filters=init_filters,\n",
        "          kernel_size=kernel_size,\n",
        "          strides=(1, 1),\n",
        "          padding=\"same\")(x)\n",
        "      x = keras.layers.BatchNormalization()(x)\n",
        "      x = keras.layers.Activation(\"relu\")(x)\n",
        "      x = keras.layers.add([x, prev_block_output])\n",
        "      prev_block_output = x\n",
        "    x = keras.layers.Conv2D(\n",
        "        filters=init_filters,\n",
        "        kernel_size=kernel_size,\n",
        "        strides=(1, 1),\n",
        "        padding=\"same\")(prev_block_output)\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "    x = keras.layers.Activation(\"relu\")(x)\n",
        "    x = keras.layers.GlobalMaxPooling2D()(x)\n",
        "    x = keras.layers.Flatten()(x)\n",
        "    x = keras.layers.Dense(units=init_filters,\n",
        "                            activation=\"relu\",\n",
        "                          kernel_regularizer=None)(x)\n",
        "    x = keras.layers.Dropout(0.2)(x)\n",
        "    outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(optimizer='Adam',\n",
        "         loss='binary_crossentropy',\n",
        "         metrics=['accuracy'])    \n",
        "    return model"
      ],
      "id": "L4VUYwMSDWYf"
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(64, 4, 6)"
      ],
      "metadata": {
        "id": "quESPUJr6Pnj"
      },
      "execution_count": 5,
      "outputs": [],
      "id": "quESPUJr6Pnj"
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    ds[0],\n",
        "    epochs=9,\n",
        "    verbose=\"auto\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab04cb40-8498-42c9-881b-4fe65c1f246e",
        "id": "SAMRXkLp6Pnl"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/9\n",
            "689/689 [==============================] - 561s 786ms/step - loss: 0.1890 - accuracy: 0.9382\n",
            "Epoch 2/9\n",
            "689/689 [==============================] - 307s 445ms/step - loss: 0.1433 - accuracy: 0.9553\n",
            "Epoch 3/9\n",
            "689/689 [==============================] - 307s 446ms/step - loss: 0.1359 - accuracy: 0.9582\n",
            "Epoch 4/9\n",
            "689/689 [==============================] - 306s 444ms/step - loss: 0.1311 - accuracy: 0.9584\n",
            "Epoch 5/9\n",
            "689/689 [==============================] - 307s 445ms/step - loss: 0.1301 - accuracy: 0.9594\n",
            "Epoch 6/9\n",
            "689/689 [==============================] - 307s 445ms/step - loss: 0.1268 - accuracy: 0.9599\n",
            "Epoch 7/9\n",
            "689/689 [==============================] - 307s 445ms/step - loss: 0.1252 - accuracy: 0.9604\n",
            "Epoch 8/9\n",
            "689/689 [==============================] - 307s 445ms/step - loss: 0.1221 - accuracy: 0.9609\n",
            "Epoch 9/9\n",
            "689/689 [==============================] - 307s 445ms/step - loss: 0.1200 - accuracy: 0.9609\n"
          ]
        }
      ],
      "id": "SAMRXkLp6Pnl"
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(ds[1])"
      ],
      "metadata": {
        "id": "2jhPFAD6Yc1k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4073db93-54a1-4e56-d251-211d28d1e48e"
      },
      "id": "2jhPFAD6Yc1k",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "173/173 [==============================] - 34s 188ms/step - loss: 0.2084 - accuracy: 0.9327\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2084464132785797, 0.932692289352417]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Conclusion\n",
        "Batch normalization did not improve accuracy. Actually, it is worse than in any of the previous attempts."
      ],
      "metadata": {
        "id": "O-aRbAoYtxdL"
      },
      "id": "O-aRbAoYtxdL"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}